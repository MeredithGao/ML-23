{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 3: Lab\n",
        "### 10 points total\n",
        "### Version 1.0"
      ],
      "metadata": {
        "id": "WLzS4q4x_CXH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PARTNER1NAME (PARTNER1JHED), PARTER2NAME (PARTNER2JHED), etc."
      ],
      "metadata": {
        "id": "eNRCplBw_IbM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions: This notebook is intended to for answering the questions in the HW3_Programming pdf. You will answer in the space provided."
      ],
      "metadata": {
        "id": "WrZhGNVU_KHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) (2 points) Plot the Cross-entropy vs. epoch curve for both the training data and the testing data. Do you see over-fitting?"
      ],
      "metadata": {
        "id": "vSIog697_Yj5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FF0riaCN9Fzr"
      },
      "outputs": [],
      "source": [
        "#TODO plot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) (4 points) Plot a confusion matrix for the test set for all the 18 languages.  What can you infer from it? What languages are confused the most?"
      ],
      "metadata": {
        "id": "TNI1BpWD_fjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO, your plot and some discussion on the plot"
      ],
      "metadata": {
        "id": "8GOW9Ve4AQ-E"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3) (4 points) So far you randomly split the dataset uniformly at random into an 80:20 partition. However, this could mean unbalanced training data since all languages might not have the same number of names in the training set. This could in turn adversely affect performance. Could you think of some way of mitigating this? Can you choose to split the dataset more intelligently? Implement your idea (you are free to use existing functions from scikit-learn or any other python library for this) and report differences in accuracy with your new method over the previous uniformly at random partition."
      ],
      "metadata": {
        "id": "YOzAGfweAWld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO, your answer"
      ],
      "metadata": {
        "id": "Qm-qRW0xAViE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}