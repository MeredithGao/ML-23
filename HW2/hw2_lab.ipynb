{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2RmbPkncn5v"
      },
      "source": [
        "# **CS 475: Machine Learning, Fall 2022**\n",
        "# **Homework 2, Lab (15 points)**\n",
        "\n",
        "**Instructions:**\n",
        "This notebook is intended to guide you through a classification task using SVMs. Please answer all questions in this notebook (you will see <font color='blue'>TODO</font> annotations for where to include your answers). There are 3 questions. For each question, you are expected to write code to train SVM models, plot figures using the plot helper function (plot_svm_kernel), and then interprete the figures. \n",
        "\n",
        "<!-- The objective of this notebook is to provide a brief introduction to support vector machines (SVMs) and explore their advantages and disadvantages in classification and regression problems. -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4bVjlk44weF"
      },
      "outputs": [],
      "source": [
        "# Auto-setup when running on Google Colab\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    !pip install openml\n",
        "\n",
        "# General imports\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import openml as oml\n",
        "from matplotlib import cm\n",
        "\n",
        "# Hide convergence warning for now\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Getting the data\n",
        "\n",
        "We are using the sklearn.datasets.make_moons for building a dataset for the svm. And, have a quick look at the data."
      ],
      "metadata": {
        "id": "SqkG9ELo5aUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X, y = make_moons(noise=0.15, random_state=0, n_samples=300)\n",
        "\n",
        "sns.scatterplot(\n",
        "    x=X[:, 0], y=X[:, 1], c=y, zorder=10, cmap=plt.cm.bwr, edgecolors='k', marker='.').set_title(\"Data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OYjTqhocguTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting helpers. Please read following function carefully, since you will use this funcion for plotting the later results\n",
        "\n",
        "#     Visualizes the SVM model given the various outputs. It plots:\n",
        "#    * All the data point, color coded by class: blue or red\n",
        "#    * The support vectors, indicated by circling the points with a black border. \n",
        "#      If the dual coefficients are known (only for kernel SVMs) if paints support vectors with high coefficients darker\n",
        "#    * The decision function as a blue-to-red gradient. It is white where the decision function is near 0.\n",
        "#    * The decision boundary as a full line, and the SVM margins (-1 and +1 values) as a dashed line\n",
        "#\n",
        "#\n",
        "def plot_svm_kernel(X, y, title, support_vectors, decision_function, dual_coef=None, show=True):\n",
        "    \"\"\"\n",
        "    Attributes:\n",
        "    X -- The training data\n",
        "    y -- The correct labels\n",
        "    title -- The plot title\n",
        "    support_vectors -- the list of the coordinates of the support vectores\n",
        "    decision_function - The decision function returned by the SVM\n",
        "    dual_coef -- The dual coefficients of all the support vectors (not relevant for LinearSVM)\n",
        "    show -- whether to plot the figure already or not\n",
        "    \"\"\"\n",
        "    # plot the line, the points, and the nearest vectors to the plane\n",
        "    #plt.figure(fignum, figsize=(5, 5))\n",
        "    plt.title(title)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, zorder=10, cmap=plt.cm.bwr, marker='.')\n",
        "    if dual_coef is not None:\n",
        "        plt.scatter(support_vectors[:, 0], support_vectors[:, 1], c=dual_coef[0, :],\n",
        "                    s=70, edgecolors='k', zorder=10, marker='.', cmap=plt.cm.bwr)\n",
        "    else:\n",
        "        plt.scatter(support_vectors[:, 0], support_vectors[:, 1], facecolors='none',\n",
        "                    s=70, edgecolors='k', zorder=10, marker='.', cmap=plt.cm.bwr)\n",
        "    plt.axis('tight')\n",
        "    x_min, x_max = -1.5, 2.5\n",
        "    y_min, y_max = -1.0, 1.5\n",
        "\n",
        "    XX, YY = np.mgrid[x_min:x_max:300j, y_min:y_max:300j]\n",
        "    Z = decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
        "\n",
        "    # Put the result into a color plot\n",
        "    Z = Z.reshape(XX.shape)\n",
        "    plt.contour(XX, YY, Z, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'],\n",
        "                levels=[-1, 0, 1])\n",
        "    plt.pcolormesh(XX, YY, Z, vmin=-1, vmax=1, cmap=plt.cm.bwr, alpha=0.1)\n",
        "\n",
        "    plt.xlim(x_min, x_max)\n",
        "    plt.ylim(y_min, y_max)\n",
        "    \n",
        "    plt.xticks(())\n",
        "    plt.yticks(())\n",
        "\n",
        "    if show:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "q7kWrtqRIjFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 1: Linear SVMs (3 points)**\n",
        "\n",
        "In this question, you should train a LinearSVC using default loss and C=0.001. Then, use the plotting fucntion provided above to plot your results. \n",
        "\n",
        "Using the given function, the plot should show the predictions for the linear SVM. The background color should show the prediction (blue or red). The full line should show the decision boundary, and the dashed line the margin. The encircled points should show the support vectors.\n"
      ],
      "metadata": {
        "id": "msxBgMamG_-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: write code to meet aforementioned question requirements\n",
        "\n",
        "#Hint: you could use class sklearn.SVC from sklearn library for the code.\n",
        "#You can use the \"support_vectors_\" and \"decision_function\" in the sklearn.SVC object"
      ],
      "metadata": {
        "id": "YMEjufXyOtk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TODO: Put your plots here: "
      ],
      "metadata": {
        "id": "Kz-KrM5jVW44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TODO: write your interpretation here (hint: does the model fit the data well? how about the support vectors?)\n",
        "\n",
        "----------------------------------\n",
        "(put your answer here)\n",
        "----------------------------------\n"
      ],
      "metadata": {
        "id": "3-JuvhRrPbcy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 2: SVMs with different kernels （5 points）**\n",
        "\n",
        "#TODO \n",
        "Train a SVM with three different kernels (linear, polynomial and RBF) and C = 1.0. Especially for RBF kernel, kernel coefficient value (gamma) is set to 2.0. Plot the results for each kernel with “plot_svm_kernel” function (3 figures expected). \n",
        "\n",
        "Using the given function, the plots should show the predictions made for the different kernels. The background color should show the prediction (blue or red). The full line should show the decision boundary, and the dashed line the margin. The encircled points should show the support vectors."
      ],
      "metadata": {
        "id": "z_8vvi-GJEZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: write code to meet aforementioned question requirements\n",
        "\n",
        "#Hint: you could use class sklearn.svm from sklearn library"
      ],
      "metadata": {
        "id": "xL8oyMNMMY-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TODO: Put your plots here "
      ],
      "metadata": {
        "id": "sayQfDdGVp9j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TODO: write your interpretation here (hint: does the model fit the data well? how about the support vectors?)"
      ],
      "metadata": {
        "id": "9JBc5RyRVPtS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 3: Visualizing the RBF models and hyperparameter space（7 points）**"
      ],
      "metadata": {
        "id": "gMhZI7liLNeJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TODO\n",
        "Try 3 very different values for C and gamma (for both values, using [1e-3,1,1e3] in this lab). For each of the 9 combinations, create the same RBF plot as before to understand what the model is doing. In particualr, first create a standard train-test split, train the model using the training data, report the train and test accuracy, and then create the RBF plot using the training data. Explain the performance results. When are you over/underfitting? Can you see this in the train and test accuracy?"
      ],
      "metadata": {
        "id": "6Hw8kPRALYV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: write code here to meet abovementioned question requirements \n",
        "\n",
        "#Hints: you could use class sklearn.model_selection from sklearn.library for build a standard stratified train-test split"
      ],
      "metadata": {
        "id": "DfKviu14NeHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TODO: Put your plots here"
      ],
      "metadata": {
        "id": "9btUIZwFWPk8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TODO: write your interpretation here (see examples below, refer to your plots when explaining what the model is doing)\n",
        "\n",
        "*   For large C, ...\n",
        "*   For small C, ...\n",
        "*   For large gamma, ...\n",
        "*   For small gamma, ...\n",
        "*   The best performing parameters are ..., where ...\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gaPvS3LZPzzc"
      }
    }
  ]
}